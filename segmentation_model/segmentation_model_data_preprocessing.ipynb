{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "from PIL import Image\n",
    "import random \n",
    "import time \n",
    "import cv2 \n",
    "import math \n",
    "import albumentations as A \n",
    "from scipy.spatial.transform import Rotation as R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_point_to_image(C,T,P): \n",
    "    P_H = np.array([[P[0]],[P[1]],[P[2]],[1]]) \n",
    "    T_H = T[:3,:4]  \n",
    "    uv = C @ T_H @ P_H \n",
    "    uv = uv / uv[2] \n",
    "    uv = uv[:2] \n",
    "    uv = uv.reshape((2)) \n",
    "    return uv \n",
    "\n",
    "def project_point_list_to_image(C,T,P_list): \n",
    "    n = len(P_list)\n",
    "    uv_list = []  \n",
    "    for P in P_list: \n",
    "        uv = project_point_to_image(C,T,P) \n",
    "        uv_list.append(uv) \n",
    "    return uv_list   \n",
    "\n",
    "def transform_pts(pts, T):  \n",
    "    pts_transformed = [] \n",
    "    for pt in pts: \n",
    "        pt = pt.reshape(3,1) \n",
    "        pt = np.vstack((pt, 1))  \n",
    "        pt_transformed = T @ pt  \n",
    "        pts_transformed.append(pt_transformed[:3]) \n",
    "    return pts_transformed\n",
    "\n",
    "def overlay_points_on_image(image, pixel_points, radius=5, color=(0, 0, 255), thickness=-1):\n",
    "    \"\"\"\n",
    "    Overlays a list of pixel points on the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input image (a NumPy array).\n",
    "    - pixel_points: A list of 2D pixel coordinates [(x1, y1), (x2, y2), ...].\n",
    "    - radius: The radius of the circle to draw around each point. Default is 5.\n",
    "    - color: The color of the circle (BGR format). Default is red (0, 0, 255).\n",
    "    - thickness: The thickness of the circle. Default is -1 to fill the circle.\n",
    "\n",
    "    Returns:\n",
    "    - The image with points overlaid.\n",
    "    \"\"\"\n",
    "    # Iterate over each pixel point and overlay it on the image\n",
    "    for point in pixel_points:\n",
    "        if point is not None:  # Only overlay valid points\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            # Draw a filled circle at the pixel coordinates\n",
    "            cv2.circle(image, (x, y), radius, color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "def compute_2D_gridpoints(N=10,s=0.1): \n",
    "    # N = num squares, s = side length  \n",
    "    u = np.linspace(-s/2, +s/2, N+1) \n",
    "    v = np.linspace(-s/2, +s/2, N+1) \n",
    "    gridpoints = [] \n",
    "    for uu in u:\n",
    "        for vv in v: \n",
    "            gridpoints.append(np.array([uu,vv,0])) \n",
    "    return gridpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS DEFINITIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datapoint:\n",
    "    def __init__(self, metadata_filepath, pose_filepath, rgb_filepath, seg_png_filepath, seg_json_filepath):\n",
    "        # Store the filepaths\n",
    "        self.metadata_filepath = metadata_filepath\n",
    "        self.pose_filepath = pose_filepath\n",
    "        self.rgb_filepath = rgb_filepath\n",
    "        self.seg_png_filepath = seg_png_filepath\n",
    "        self.seg_json_filepath = seg_json_filepath\n",
    "        \n",
    "        self.read_files()\n",
    "        self.read_pose_data() \n",
    "        # self.compute_keypoints() \n",
    "\n",
    "        # TODO: self.idx = get_index() # or given as input \n",
    "\n",
    "    def read_files(self): \n",
    "        # Read the actual data from files and store it\n",
    "        self.metadata = self._read_json(self.metadata_filepath) if self.metadata_filepath else None\n",
    "        self.pose = self._read_json(self.pose_filepath) if self.pose_filepath else None\n",
    "        self.rgb = self._read_rgb(self.rgb_filepath) if self.rgb_filepath else None\n",
    "        self.seg_png = self._read_segmentation_png(self.seg_png_filepath) if self.seg_png_filepath else None\n",
    "        self.seg_json = self._read_segmentation_json(self.seg_json_filepath) if self.seg_json_filepath else None \n",
    "\n",
    "    def read_pose_data(self): \n",
    "        # read pose data from pose json file \n",
    "        self.cam_pose = np.array([\n",
    "                            [1, 0, 0, 0],\n",
    "                            [0, -1, 0, 0],\n",
    "                            [0, 0, -1, 0],\n",
    "                            [0, 0, 0, 1]\n",
    "                        ]) # NOTE: cam pose from isaac sim appears to be offset \n",
    "        self.tag_pose = np.array(self.pose[\"tag\"]).transpose()  \n",
    "        self.tag_pose *= np.array([\n",
    "                            [10,10,10,1],\n",
    "                            [10,10,10,1],\n",
    "                            [10,10,10,1],\n",
    "                            [1,1,1,1]\n",
    "                        ]) # rescale the tag, FIXME: avoid hardcoding tag scale value \n",
    "        self.light_pose = self.pose[\"light\"]\n",
    "        self.tag_xyzabc = np.hstack((np.array(self.tag_pose[:3,3]), R.from_matrix(self.tag_pose[:3,:3]).as_euler(\"xyz\",degrees=True))) # tag position in world frame \n",
    "\n",
    "    def compute_keypoints(self): \n",
    "        # FIXME: avoid hardcoding and take in as arguments \n",
    "        # camera parameters \n",
    "        width = 640 \n",
    "        height = 480 \n",
    "        focal_length = 24.0 \n",
    "        horiz_aperture = 20.955\n",
    "        # Pixels are square so we can do:\n",
    "        vert_aperture = height/width * horiz_aperture\n",
    "        fov = 2 * math.atan(horiz_aperture / (2 * focal_length))\n",
    "        # compute focal point and center\n",
    "        fx = width * focal_length / horiz_aperture\n",
    "        fy = height * focal_length / vert_aperture\n",
    "        cx = width / 2\n",
    "        cy = height /2 \n",
    "\n",
    "        self.C = np.array([\n",
    "            [fx,0,cx],\n",
    "            [0,fy,cy],\n",
    "            [0,0,1]\n",
    "        ])\n",
    "\n",
    "        s = 0.1 # side length of marker \n",
    "        keypoints_tag_frame = compute_2D_gridpoints(N=10, s=s) \n",
    "\n",
    "        # transformations \n",
    "        tf_w_t = self.tag_pose \n",
    "        tf_w_c = self.cam_pose \n",
    "        tf_c_w = np.linalg.inv(tf_w_c) \n",
    "\n",
    "        keypoints_world_frame = [] \n",
    "        for kp_t in keypoints_tag_frame: \n",
    "            kp_t_homog = np.hstack((kp_t,np.array([1]))).reshape(4,1)\n",
    "            kp_w_homog = tf_w_t @ kp_t_homog \n",
    "            keypoints_world_frame.append(kp_w_homog[:3].reshape(3)) \n",
    "\n",
    "        self.keypoints_image_space = project_point_list_to_image(self.C,tf_c_w,keypoints_world_frame) \n",
    "\n",
    "    def _read_json(self, filepath):\n",
    "        \"\"\"Read and parse JSON files.\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def _read_rgb(self, filepath):\n",
    "        \"\"\"Placeholder for reading RGB image files.\"\"\"\n",
    "        return filepath  # Placeholder: returning the file path to avoid memory overload\n",
    "\n",
    "    def _read_segmentation_png(self, filepath):\n",
    "        \"\"\"Placeholder for reading segmentation PNG image files.\"\"\"\n",
    "        return filepath  # Placeholder: returning the file path to avoid memory overload\n",
    "\n",
    "    def _read_segmentation_json(self, filepath):\n",
    "        \"\"\"Read segmentation JSON files.\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def compute_diffusion_reflectance(self): \n",
    "        \"\"\"Compute the diffuse reflection based on pose and metadata.\"\"\"\n",
    "        N = np.array(self.tag_pose)[:3,2] \n",
    "        L = np.array(self.light_pose)[:3,2] \n",
    "        V = np.array(self.cam_pose)[:3,2] \n",
    "        light_exposure = self.metadata[\"light\"][\"exposure\"] \n",
    "        I_incident = 2**light_exposure \n",
    "        shininess = 1.0  # Placeholder value \n",
    "        self.diffuse_reflection = I_incident * max(np.dot(N, L), 0)\n",
    "\n",
    "    def preprocess_seg_img(self):\n",
    "        \"\"\"\n",
    "        Preprocesses the segmentation image by resizing and converting it to a binary mask based on tag color.\n",
    "        \"\"\"\n",
    "\n",
    "        seg_img_path = self.seg_png_filepath \n",
    "        seg_json_path = self.seg_json_filepath \n",
    "\n",
    "        # Validate that the segmentation image file exists\n",
    "        if not os.path.exists(seg_img_path):\n",
    "            raise FileNotFoundError(f\"Segmentation image file not found: {seg_img_path}\")\n",
    "\n",
    "        # Validate that the JSON file exists\n",
    "        if not os.path.exists(seg_json_path):\n",
    "            raise FileNotFoundError(f\"Segmentation JSON file not found: {seg_json_path}\")\n",
    "\n",
    "        # Load the segmentation JSON data \n",
    "        with open(seg_json_path, 'r') as json_file:\n",
    "            seg_json = json.load(json_file)\n",
    "\n",
    "            # Find the tag color from the JSON data\n",
    "            for key, val in seg_json.items(): \n",
    "                if val.get(\"class\") == \"tag0\":  \n",
    "                    # Convert the key (which is a string representing a tuple) into an actual tuple\n",
    "                    tag_seg_color = tuple(map(int, key.strip('()').split(', ')))  # Convert string '(140, 25, 255, 255)' into a tuple (140, 25, 255, 255)\n",
    "                    break\n",
    "            else:\n",
    "                # raise ValueError(\"Tag with class 'tag0' not found in JSON.\")\n",
    "                tag_seg_color = tuple([-1,-1,-1,-1]) # impossible color value # FIXME: this is a workaround which can be turned into something more elegant \n",
    "\n",
    "        # Load and resize the segmentation image\n",
    "        seg_img = Image.open(seg_img_path)\n",
    "        # new_size = (480, 270)\n",
    "        # new_size = (480*2, 270*2)\n",
    "        # seg_img_resized = seg_img.resize(new_size)\n",
    "        seg_img_resized = seg_img\n",
    "\n",
    "        # Convert the resized image to a NumPy array\n",
    "        seg_img_resized = np.array(seg_img_resized)\n",
    "\n",
    "        # Check if the image is RGB (3 channels) or RGBA (4 channels) or grayscale (1 channel)\n",
    "        if len(seg_img_resized.shape) == 3:\n",
    "            if seg_img_resized.shape[2] == 3:  # RGB image\n",
    "                # Compare each pixel to the tag color (e.g., RGB triplet)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color[:3], axis=-1)  # Create binary mask for RGB image\n",
    "            elif seg_img_resized.shape[2] == 4:  # RGBA image\n",
    "                # Compare each pixel to the tag color (RGBA)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color, axis=-1)  # Create binary mask for RGBA image\n",
    "        else:  # If it's a single channel (grayscale), use it directly\n",
    "            seg_img_resized = seg_img_resized == tag_seg_color  # Compare pixel values directly\n",
    "\n",
    "        # Convert the binary mask to uint8 type (0 or 1)\n",
    "        seg_img_resized = (seg_img_resized).astype(np.uint8) * 255  # Multiply by 255 to match image range\n",
    "\n",
    "        # Convert the binary mask back to an image\n",
    "        seg_img_resized = Image.fromarray(seg_img_resized)\n",
    "\n",
    "        return seg_img_resized\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Custom representation for the datapoint object.\"\"\"\n",
    "        # return f\"datapoint(metadata_filepath={self.metadata_filepath}, pose_filepath={self.pose_filepath}, rgb_filepath={self.rgb_filepath}, seg_png_filepath={self.seg_png_filepath}, seg_json_filepath={self.seg_json_filepath})\"\n",
    "        description = [\n",
    "            f\"lighting_exposure={self.metadata[\"light\"][\"exposure\"]:.2f}\",\n",
    "            # f\"lighting_color={str(self.metadata[\"light\"][\"color\"]) }\" # FIXME: reduce to two decimal places \n",
    "            f\"lighting_color=({self.metadata[\"light\"][\"color\"][0]:.2f},{self.metadata[\"light\"][\"color\"][1]:.2f},{self.metadata[\"light\"][\"color\"][2]:.2f})\" # FIXME: reduce to two decimal places \n",
    "        ]\n",
    "        return \"\\n\".join(description) \n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data_folders, out_dir):\n",
    "        self.data_folders = data_folders\n",
    "        self.out_dir = out_dir\n",
    "        self.datapoints = []\n",
    "        self.datapoints_train = []\n",
    "        self.datapoints_val = []\n",
    "\n",
    "    def _get_files_in_subfolder(self, folder, file_extension=None):\n",
    "        \"\"\"Helper method to get files in a subfolder, with an optional file extension filter.\"\"\"\n",
    "        files_list = os.listdir(folder)\n",
    "        if file_extension:\n",
    "            files_list = [file for file in files_list if file.endswith(file_extension)]\n",
    "        # Order files_list by date created\n",
    "        files_list = sorted(files_list, key=lambda x: os.path.getctime(os.path.join(folder, x)))  # Assumes creation dates are synchronized\n",
    "        return files_list\n",
    "\n",
    "    def process_folders(self):\n",
    "        \"\"\"Process the folders and create datapoint objects.\"\"\"\n",
    "        for data_folder in self.data_folders:\n",
    "            metadata_subfolder = os.path.join(data_folder, \"metadata\")\n",
    "            pose_subfolder = os.path.join(data_folder, \"pose\")\n",
    "            rgb_subfolder = os.path.join(data_folder, \"rgb\")\n",
    "            seg_subfolder = os.path.join(data_folder, \"seg\")\n",
    "\n",
    "            # List files in subfolders \n",
    "            metadata_files = self._get_files_in_subfolder(metadata_subfolder, file_extension=\".json\")\n",
    "            pose_files = self._get_files_in_subfolder(pose_subfolder, file_extension=\".json\")\n",
    "            rgb_files = self._get_files_in_subfolder(rgb_subfolder, file_extension=\".png\")\n",
    "            seg_png_files = self._get_files_in_subfolder(seg_subfolder, file_extension=\".png\")\n",
    "            seg_json_files = self._get_files_in_subfolder(seg_subfolder, file_extension=\".json\")\n",
    "\n",
    "            # Make sure the files are indexed and aligned properly (by index) across the subfolders\n",
    "            max_length = max(len(metadata_files), len(pose_files), len(rgb_files), len(seg_png_files), len(seg_json_files))\n",
    "\n",
    "            # Verify that the lengths are the same\n",
    "            if not all(len(files) == max_length for files in [metadata_files, pose_files, rgb_files, seg_png_files, seg_json_files]):\n",
    "                print(f\"Lengths do not match for folder: {data_folder}\")\n",
    "                continue\n",
    "\n",
    "            for i in range(max_length):\n",
    "                # Use index 'i' to fetch corresponding files. If a file doesn't exist, use None.\n",
    "                metadata_filepath = os.path.join(metadata_subfolder, metadata_files[i]) if i < len(metadata_files) else None\n",
    "                pose_filepath = os.path.join(pose_subfolder, pose_files[i]) if i < len(pose_files) else None\n",
    "                rgb_filepath = os.path.join(rgb_subfolder, rgb_files[i]) if i < len(rgb_files) else None\n",
    "                seg_png_filepath = os.path.join(seg_subfolder, seg_png_files[i]) if i < len(seg_png_files) else None\n",
    "                seg_json_filepath = os.path.join(seg_subfolder, seg_json_files[i]) if i < len(seg_json_files) else None\n",
    "\n",
    "                # Create a datapoint object for each corresponding file\n",
    "                data_point = datapoint(metadata_filepath, pose_filepath, rgb_filepath, seg_png_filepath, seg_json_filepath)\n",
    "                self.datapoints.append(data_point)\n",
    "\n",
    "    def get_datapoints(self):\n",
    "        \"\"\"Return the list of datapoint objects.\"\"\"\n",
    "        return self.datapoints\n",
    "    \n",
    "    def get_datapoints_filtered(self):\n",
    "        \"\"\"Return the list of filtered datapoint objects.\"\"\"\n",
    "        return self.datapoints_filtered \n",
    "    \n",
    "    def check_image_okay(self, rgb_img, seg_img, min_tag_area=1000, min_tag_pix_mean=75, max_tag_pix_mean=250): \n",
    "        seg_img = np.array(seg_img) \n",
    "        # compute pixel area of tag segmentation \n",
    "        tag_pix_area = np.sum(seg_img == 255) \n",
    "\n",
    "        # create list of marker pixels using segmentation \n",
    "        marker_pixels = np.argwhere(seg_img == 255)  # Get the indices of pixels where the tag is present \n",
    "        # compute contrast of marker pixels using rgb image \n",
    "        rgb_img = np.array(rgb_img) \n",
    "        marker_rgb_values = rgb_img[marker_pixels[:, 0], marker_pixels[:, 1]]  # Get the RGB values of the marker pixels \n",
    "        marker_grey_values = np.mean(marker_rgb_values, axis=1)  # Compute the mean RGB values of the marker pixels \n",
    "        # compute contrast as the difference in magnitude of the RGB values of the marker pixels \n",
    "        tag_pix_contrast = marker_grey_values.max() - marker_grey_values.min()  \n",
    "        tag_pix_mean = marker_grey_values.mean()\n",
    "        if tag_pix_area > min_tag_area and tag_pix_mean > min_tag_pix_mean and tag_pix_mean < max_tag_pix_mean:  # FIXME: hardcoded threshold for tag area and diffuse reflection \n",
    "            bool_image_ok = True \n",
    "        else:\n",
    "            bool_image_ok = False\n",
    "        return bool_image_ok\n",
    "\n",
    "    def filter_datapoints(self, min_tag_area=1000, min_tag_pix_mean=75, max_tag_pix_mean=250): \n",
    "        \"\"\"Compute the diffusion reflectance and only keep datapoints with positive values.\"\"\"\n",
    "        self.datapoints_filtered = [] \n",
    "        self.datapoints_filtered_out = [] \n",
    "        for idx, dp in enumerate(self.datapoints):\n",
    "            dp.compute_diffusion_reflectance() \n",
    "            seg_img = dp.preprocess_seg_img() \n",
    "            seg_img = np.array(seg_img) \n",
    "            # compute pixel area of tag segmentation \n",
    "            dp.tag_pix_area = np.sum(seg_img == 255) \n",
    "            self.datapoints[idx].tag_pix_area = np.sum(seg_img == 255) \n",
    "\n",
    "            # create list of marker pixels using segmentation \n",
    "            marker_pixels = np.argwhere(seg_img == 255)  # Get the indices of pixels where the tag is present \n",
    "            # compute contrast of marker pixels using rgb image \n",
    "            rgb_img = Image.open(dp.rgb_filepath) \n",
    "            rgb_img = np.array(rgb_img) \n",
    "            marker_rgb_values = rgb_img[marker_pixels[:, 0], marker_pixels[:, 1]]  # Get the RGB values of the marker pixels \n",
    "            marker_grey_values = np.mean(marker_rgb_values, axis=1)  # Compute the mean RGB values of the marker pixels \n",
    "            # compute contrast as the difference in magnitude of the RGB values of the marker pixels \n",
    "            dp.tag_pix_contrast = marker_grey_values.max() - marker_grey_values.min()  \n",
    "            self.datapoints[idx].tag_pix_contrast = marker_grey_values.max() - marker_grey_values.min() \n",
    "            self.datapoints[idx].tag_pix_mean = marker_grey_values.mean()\n",
    "            dp.tag_pix_mean = marker_grey_values.mean() \n",
    "\n",
    "            # os.makedirs(os.path.join(self.out_dir, \"contrast\"), exist_ok=True) \n",
    "            # # save contrast image for debugging purposes\n",
    "            # cv2.imwrite(os.path.join(self.out_dir, \"contrast\", f\"contrast_{idx}_{dp.tag_pix_contrast}_{dp.tag_pix_mean}.png\"), rgb_img) \n",
    "            if self.check_image_okay(rgb_img, seg_img, min_tag_area=min_tag_area, min_tag_pix_mean=min_tag_pix_mean, max_tag_pix_mean=max_tag_pix_mean): \n",
    "                self.datapoints_filtered.append(dp)\n",
    "            else: \n",
    "                self.datapoints_filtered_out.append(dp)\n",
    "\n",
    "            # if dp.diffuse_reflection > min_diffuse_reflection and dp.tag_pix_area > min_tag_area and dp.tag_pix_mean > min_tag_pix_mean and dp.tag_pix_mean < max_tax_pix_mean:  # FIXME: hardcoded threshold for tag area and diffuse reflection \n",
    "            #     self.datapoints_filtered.append(dp) \n",
    "            # else: \n",
    "            #     self.datapoints_filtered_out.append(dp) \n",
    "                \n",
    "    def split_train_val(self, filter=True, frac_train=0.8):\n",
    "        \"\"\"Split the datapoints into training and validation datasets.\"\"\"\n",
    "        if filter: \n",
    "            self.datapoints_train = random.sample(self.datapoints_filtered, int(frac_train * len(self.datapoints_filtered)))\n",
    "            self.datapoints_val = [dp for dp in self.datapoints_filtered if dp not in self.datapoints_train]\n",
    "        else:\n",
    "            self.datapoints_train = random.sample(self.datapoints, int(frac_train * len(self.datapoints)))\n",
    "            self.datapoints_val = [dp for dp in self.datapoints if dp not in self.datapoints_train]\n",
    "\n",
    "    def create_directories(self):\n",
    "        \"\"\"Create directories for training and validation data.\"\"\"\n",
    "        dir_train = os.path.join(self.out_dir, \"train\")\n",
    "        dir_val = os.path.join(self.out_dir, \"val\")\n",
    "        dir_train_rgb = os.path.join(dir_train, \"rgb\")\n",
    "        dir_train_seg = os.path.join(dir_train, \"seg\")\n",
    "        dir_val_rgb = os.path.join(dir_val, \"rgb\")\n",
    "        dir_val_seg = os.path.join(dir_val, \"seg\")\n",
    "\n",
    "        os.makedirs(dir_train_rgb, exist_ok=True)\n",
    "        os.makedirs(dir_train_seg, exist_ok=True)\n",
    "        os.makedirs(dir_val_rgb, exist_ok=True)\n",
    "        os.makedirs(dir_val_seg, exist_ok=True)\n",
    "\n",
    "        return dir_train_rgb, dir_train_seg, dir_val_rgb, dir_val_seg\n",
    "\n",
    "    def preprocess_rgb(self, img_path):  \n",
    "        \"\"\"Preprocess RGB image by resizing it.\"\"\"\n",
    "        # new_size = (480, 270)  # Define the new size\n",
    "        # new_size = (480*2, 270*2)  # Define the new size\n",
    "        img = Image.open(img_path)\n",
    "        # img_resized = img.resize(new_size)\n",
    "        img_resized = img \n",
    "        return img_resized\n",
    "\n",
    "    def preprocess_seg_img(self, seg_img_path, seg_json_path, tag_seg_color=None):\n",
    "        \"\"\"\n",
    "        Preprocesses the segmentation image by resizing and converting it to a binary mask based on tag color.\n",
    "        \"\"\"\n",
    "        # Validate that the segmentation image file exists\n",
    "        if not os.path.exists(seg_img_path):\n",
    "            raise FileNotFoundError(f\"Segmentation image file not found: {seg_img_path}\")\n",
    "\n",
    "        # Validate that the JSON file exists\n",
    "        if not os.path.exists(seg_json_path):\n",
    "            raise FileNotFoundError(f\"Segmentation JSON file not found: {seg_json_path}\")\n",
    "\n",
    "        # Load the segmentation JSON data if tag_seg_color is not provided\n",
    "        if tag_seg_color is None:\n",
    "            with open(seg_json_path, 'r') as json_file:\n",
    "                seg_json = json.load(json_file)\n",
    "\n",
    "            # Find the tag color from the JSON data\n",
    "            for key, val in seg_json.items(): \n",
    "                if val.get(\"class\") == \"tag0\":  \n",
    "                    # Convert the key (which is a string representing a tuple) into an actual tuple\n",
    "                    tag_seg_color = tuple(map(int, key.strip('()').split(', ')))  # Convert string '(140, 25, 255, 255)' into a tuple (140, 25, 255, 255)\n",
    "                    break\n",
    "            else:\n",
    "                # raise ValueError(\"Tag with class 'tag0' not found in JSON.\")\n",
    "                tag_seg_color = tuple([-1,-1,-1,-1]) # impossible color value # FIXME: this is a workaround which can be turned into something more elegant \n",
    "\n",
    "        # Load and resize the segmentation image\n",
    "        seg_img = Image.open(seg_img_path)\n",
    "        # new_size = (480, 270)\n",
    "        # new_size = (480*2, 270*2)\n",
    "        # seg_img_resized = seg_img.resize(new_size)\n",
    "        seg_img_resized = seg_img\n",
    "\n",
    "        # Convert the resized image to a NumPy array\n",
    "        seg_img_resized = np.array(seg_img_resized)\n",
    "\n",
    "        # Check if the image is RGB (3 channels) or RGBA (4 channels) or grayscale (1 channel)\n",
    "        if len(seg_img_resized.shape) == 3:\n",
    "            if seg_img_resized.shape[2] == 3:  # RGB image\n",
    "                # Compare each pixel to the tag color (e.g., RGB triplet)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color[:3], axis=-1)  # Create binary mask for RGB image\n",
    "            elif seg_img_resized.shape[2] == 4:  # RGBA image\n",
    "                # Compare each pixel to the tag color (RGBA)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color, axis=-1)  # Create binary mask for RGBA image\n",
    "        else:  # If it's a single channel (grayscale), use it directly\n",
    "            seg_img_resized = seg_img_resized == tag_seg_color  # Compare pixel values directly\n",
    "\n",
    "        # Convert the binary mask to uint8 type (0 or 1)\n",
    "        seg_img_resized = (seg_img_resized).astype(np.uint8) * 255  # Multiply by 255 to match image range\n",
    "\n",
    "        # Convert the binary mask back to an image\n",
    "        seg_img_resized = Image.fromarray(seg_img_resized)\n",
    "\n",
    "        return seg_img_resized\n",
    "\n",
    "    def save_preprocessed_images(self, frac_train=0.8, augmentation=True):\n",
    "        \"\"\"Loop through train and val datapoints and save preprocessed images and segmentation masks.\"\"\"\n",
    "        dir_train_rgb, dir_train_seg, dir_val_rgb, dir_val_seg = self.create_directories()\n",
    "\n",
    "        if augmentation: \n",
    "            transform = A.Compose([\n",
    "                A.RandomShadow(shadow_roi=(0,0,1,1), num_shadows_limit=(1,2), shadow_dimension=4, shadow_intensity_range =(0.5, 0.8), p=0.8),  # Apply random shadows to the image\n",
    "                A.RandomSunFlare(flare_roi=(0,0,1,1), num_flare_circles_range=(10,50), src_radius=100, src_color=(150,150,150), method=\"physics_based\", p=0.8),  # Apply random sun flare to the image, TODO: come back to this, get labels \n",
    "                A.GaussNoise(var_limit=(0,0.05), per_channel=True, p=1),  # Add noise to the image \n",
    "                A.AdvancedBlur(blur_limit=(5,25), p=0.8),  # Apply blur to the image \n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.8),  # Apply gamma correction to the image\n",
    "                A.RandomBrightnessContrast(brightness_limit=(-0.25,0.25), contrast_limit=(-0.95,0.95), p=0.8),  # Adjust brightness and contrast\n",
    "                A.ISONoise(intensity=(0.1, 0.5), color_shift=(0.01, 0.05), p=0.8),  # Apply ISO noise to the image \n",
    "            ])\n",
    "\n",
    "        for i, dp in enumerate(self.datapoints_train): \n",
    "            img = self.preprocess_rgb(dp.rgb_filepath) \n",
    "            seg = self.preprocess_seg_img(dp.seg_png_filepath, dp.seg_json_filepath)   \n",
    "            if augmentation: \n",
    "                augmented_img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image']) \n",
    "                while not self.check_image_okay(augmented_img, seg, min_tag_area=1000, min_tag_pix_mean=75, max_tag_pix_mean=250): \n",
    "                    augmented_img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image']) \n",
    "                # img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image'])       \n",
    "                img = augmented_img \n",
    "\n",
    "            img.save(os.path.join(dir_train_rgb, f\"img_{i}.png\")) \n",
    "            seg.save(os.path.join(dir_train_seg, f\"seg_{i}.png\"))\n",
    "\n",
    "        for i, dp in enumerate(self.datapoints_val):\n",
    "            img = self.preprocess_rgb(dp.rgb_filepath) \n",
    "            seg = self.preprocess_seg_img(dp.seg_png_filepath, dp.seg_json_filepath) \n",
    "            if augmentation: \n",
    "                img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image'])       \n",
    "            img.save(os.path.join(dir_val_rgb, f\"img_{i}.png\")) \n",
    "            seg.save(os.path.join(dir_val_seg, f\"seg_{i}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 1001\n",
      "Number of filtered datapoints: 669\n"
     ]
    }
   ],
   "source": [
    "data_folders = [\n",
    "    \"/home/anegi/abhay_ws/marker_detection_failure_recovery/output/markers_20250305-165003\",\n",
    "    \"/home/anegi/abhay_ws/marker_detection_failure_recovery/output/markers_20250310-005350/\", \n",
    "]\n",
    "\n",
    "# define OUT_DIR based on current date and time \n",
    "OUT_DIR = f\"/home/anegi/abhay_ws/marker_detection_failure_recovery/segmentation_model/data/data_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "# OUT_DIR = f\"C:/Users/NegiA/Desktop/abhay_ws/marker_detection_failure_recovery/segmentation_model/sim_data/markers_20250314-181037/outputs/data_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "# OUT_DIR = f\"/media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/markers_20250305-165003/segmentation_model_data_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True) \n",
    "\n",
    "# Create an instance of the DataProcessor class\n",
    "processor = DataProcessor(data_folders, OUT_DIR)\n",
    "\n",
    "# Process the folders to create the datapoint list\n",
    "processor.process_folders()\n",
    "\n",
    "# Retrieve and print length of the datapoints before and after filtering \n",
    "print(f\"Number of datapoints: {len(processor.datapoints)}\") \n",
    "processor.filter_datapoints() \n",
    "print(f\"Number of filtered datapoints: {len(processor.datapoints_filtered)}\")  \n",
    "\n",
    "# Retrieve filtered datapoints\n",
    "datapoints = processor.get_datapoints_filtered()\n",
    "\n",
    "# Split the datapoints into training and validation sets\n",
    "frac_train = 0.8\n",
    "processor.split_train_val(filter=True, frac_train=frac_train) \n",
    "processor.save_preprocessed_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
