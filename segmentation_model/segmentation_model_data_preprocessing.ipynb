{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "import json \n",
    "from PIL import Image\n",
    "import random \n",
    "import time \n",
    "import cv2 \n",
    "import math \n",
    "import albumentations as A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_point_to_image(C,T,P): \n",
    "    P_H = np.array([[P[0]],[P[1]],[P[2]],[1]]) \n",
    "    T_H = T[:3,:4]  \n",
    "    uv = C @ T_H @ P_H \n",
    "    uv = uv / uv[2] \n",
    "    uv = uv[:2] \n",
    "    uv = uv.reshape((2)) \n",
    "    return uv \n",
    "\n",
    "def project_point_list_to_image(C,T,P_list): \n",
    "    n = len(P_list)\n",
    "    uv_list = []  \n",
    "    for P in P_list: \n",
    "        uv = project_point_to_image(C,T,P) \n",
    "        uv_list.append(uv) \n",
    "    return uv_list   \n",
    "\n",
    "def transform_pts(pts, T):  \n",
    "    pts_transformed = [] \n",
    "    for pt in pts: \n",
    "        pt = pt.reshape(3,1) \n",
    "        pt = np.vstack((pt, 1))  \n",
    "        pt_transformed = T @ pt  \n",
    "        pts_transformed.append(pt_transformed[:3]) \n",
    "    return pts_transformed\n",
    "\n",
    "def overlay_points_on_image(image, pixel_points, radius=5, color=(0, 0, 255), thickness=-1):\n",
    "    \"\"\"\n",
    "    Overlays a list of pixel points on the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input image (a NumPy array).\n",
    "    - pixel_points: A list of 2D pixel coordinates [(x1, y1), (x2, y2), ...].\n",
    "    - radius: The radius of the circle to draw around each point. Default is 5.\n",
    "    - color: The color of the circle (BGR format). Default is red (0, 0, 255).\n",
    "    - thickness: The thickness of the circle. Default is -1 to fill the circle.\n",
    "\n",
    "    Returns:\n",
    "    - The image with points overlaid.\n",
    "    \"\"\"\n",
    "    # Iterate over each pixel point and overlay it on the image\n",
    "    for point in pixel_points:\n",
    "        if point is not None:  # Only overlay valid points\n",
    "            x, y = int(point[0]), int(point[1])\n",
    "            # Draw a filled circle at the pixel coordinates\n",
    "            cv2.circle(image, (x, y), radius, color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "def compute_2D_gridpoints(N=10,s=0.1): \n",
    "    # N = num squares, s = side length  \n",
    "    u = np.linspace(-s/2, +s/2, N+1) \n",
    "    v = np.linspace(-s/2, +s/2, N+1) \n",
    "    gridpoints = [] \n",
    "    for uu in u:\n",
    "        for vv in v: \n",
    "            gridpoints.append(np.array([uu,vv,0])) \n",
    "    return gridpoints "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASS DEFINITIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datapoint:\n",
    "    def __init__(self, metadata_filepath, pose_filepath, rgb_filepath, seg_png_filepath, seg_json_filepath):\n",
    "        # Store the filepaths\n",
    "        self.metadata_filepath = metadata_filepath\n",
    "        self.pose_filepath = pose_filepath\n",
    "        self.rgb_filepath = rgb_filepath\n",
    "        self.seg_png_filepath = seg_png_filepath\n",
    "        self.seg_json_filepath = seg_json_filepath\n",
    "        \n",
    "        self.read_files()\n",
    "        self.read_pose_data() \n",
    "        # self.compute_keypoints() \n",
    "\n",
    "        # TODO: self.idx = get_index() # or given as input \n",
    "\n",
    "    def read_files(self): \n",
    "        # Read the actual data from files and store it\n",
    "        self.metadata = self._read_json(self.metadata_filepath) if self.metadata_filepath else None\n",
    "        self.pose = self._read_json(self.pose_filepath) if self.pose_filepath else None\n",
    "        self.rgb = self._read_rgb(self.rgb_filepath) if self.rgb_filepath else None\n",
    "        self.seg_png = self._read_segmentation_png(self.seg_png_filepath) if self.seg_png_filepath else None\n",
    "        self.seg_json = self._read_segmentation_json(self.seg_json_filepath) if self.seg_json_filepath else None \n",
    "\n",
    "    def read_pose_data(self): \n",
    "        # read pose data from pose json file \n",
    "        self.cam_pose = np.array([\n",
    "                            [1, 0, 0, 0],\n",
    "                            [0, -1, 0, 0],\n",
    "                            [0, 0, -1, 0],\n",
    "                            [0, 0, 0, 1]\n",
    "                        ]) # NOTE: cam pose from isaac sim appears to be offset \n",
    "        self.tag_pose = np.array(self.pose[\"tag\"]).transpose()  \n",
    "        self.tag_pose *= np.array([\n",
    "                            [10,10,10,1],\n",
    "                            [10,10,10,1],\n",
    "                            [10,10,10,1],\n",
    "                            [1,1,1,1]\n",
    "                        ]) # rescale the tag, FIXME: avoid hardcoding tag scale value \n",
    "        self.light_pose = self.pose[\"light\"]\n",
    "        \n",
    "    def compute_keypoints(self): \n",
    "        # FIXME: avoid hardcoding and take in as arguments \n",
    "        # camera parameters \n",
    "        width = 640 \n",
    "        height = 480 \n",
    "        focal_length = 24.0 \n",
    "        horiz_aperture = 20.955\n",
    "        # Pixels are square so we can do:\n",
    "        vert_aperture = height/width * horiz_aperture\n",
    "        fov = 2 * math.atan(horiz_aperture / (2 * focal_length))\n",
    "        # compute focal point and center\n",
    "        fx = width * focal_length / horiz_aperture\n",
    "        fy = height * focal_length / vert_aperture\n",
    "        cx = width / 2\n",
    "        cy = height /2 \n",
    "\n",
    "        self.C = np.array([\n",
    "            [fx,0,cx],\n",
    "            [0,fy,cy],\n",
    "            [0,0,1]\n",
    "        ])\n",
    "\n",
    "        s = 0.1 # side length of marker \n",
    "        keypoints_tag_frame = compute_2D_gridpoints(N=10, s=s) \n",
    "\n",
    "        # transformations \n",
    "        tf_w_t = self.tag_pose \n",
    "        tf_w_c = self.cam_pose \n",
    "        tf_c_w = np.linalg.inv(tf_w_c) \n",
    "\n",
    "        keypoints_world_frame = [] \n",
    "        for kp_t in keypoints_tag_frame: \n",
    "            kp_t_homog = np.hstack((kp_t,np.array([1]))).reshape(4,1)\n",
    "            kp_w_homog = tf_w_t @ kp_t_homog \n",
    "            keypoints_world_frame.append(kp_w_homog[:3].reshape(3)) \n",
    "\n",
    "        self.keypoints_image_space = project_point_list_to_image(self.C,tf_c_w,keypoints_world_frame) \n",
    "\n",
    "    def _read_json(self, filepath):\n",
    "        \"\"\"Read and parse JSON files.\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def _read_rgb(self, filepath):\n",
    "        \"\"\"Placeholder for reading RGB image files.\"\"\"\n",
    "        return filepath  # Placeholder: returning the file path to avoid memory overload\n",
    "\n",
    "    def _read_segmentation_png(self, filepath):\n",
    "        \"\"\"Placeholder for reading segmentation PNG image files.\"\"\"\n",
    "        return filepath  # Placeholder: returning the file path to avoid memory overload\n",
    "\n",
    "    def _read_segmentation_json(self, filepath):\n",
    "        \"\"\"Read segmentation JSON files.\"\"\"\n",
    "        with open(filepath, 'r') as file:\n",
    "            return json.load(file)\n",
    "\n",
    "    def compute_diffusion_reflectance(self): \n",
    "        \"\"\"Compute the diffuse reflection based on pose and metadata.\"\"\"\n",
    "        N = np.array(self.tag_pose)[:3,2] \n",
    "        L = np.array(self.light_pose)[:3,2] \n",
    "        V = np.array(self.cam_pose)[:3,2] \n",
    "        light_exposure = self.metadata[\"light\"][\"exposure\"] \n",
    "        I_incident = 2**light_exposure \n",
    "        shininess = 1.0  # Placeholder value \n",
    "        self.diffuse_reflection = I_incident * max(np.dot(N, L), 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Custom representation for the datapoint object.\"\"\"\n",
    "        # return f\"datapoint(metadata_filepath={self.metadata_filepath}, pose_filepath={self.pose_filepath}, rgb_filepath={self.rgb_filepath}, seg_png_filepath={self.seg_png_filepath}, seg_json_filepath={self.seg_json_filepath})\"\n",
    "        description = [\n",
    "            f\"lighting_exposure={self.metadata[\"light\"][\"exposure\"]:.2f}\",\n",
    "            # f\"lighting_color={str(self.metadata[\"light\"][\"color\"]) }\" # FIXME: reduce to two decimal places \n",
    "            f\"lighting_color=({self.metadata[\"light\"][\"color\"][0]:.2f},{self.metadata[\"light\"][\"color\"][1]:.2f},{self.metadata[\"light\"][\"color\"][2]:.2f})\" # FIXME: reduce to two decimal places \n",
    "        ]\n",
    "        return \"\\n\".join(description) \n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data_folders, out_dir):\n",
    "        self.data_folders = data_folders\n",
    "        self.out_dir = out_dir\n",
    "        self.datapoints = []\n",
    "        self.datapoints_train = []\n",
    "        self.datapoints_val = []\n",
    "\n",
    "    def _get_files_in_subfolder(self, folder, file_extension=None):\n",
    "        \"\"\"Helper method to get files in a subfolder, with an optional file extension filter.\"\"\"\n",
    "        files_list = os.listdir(folder)\n",
    "        if file_extension:\n",
    "            files_list = [file for file in files_list if file.endswith(file_extension)]\n",
    "        # Order files_list by date created\n",
    "        files_list = sorted(files_list, key=lambda x: os.path.getctime(os.path.join(folder, x)))  # Assumes creation dates are synchronized\n",
    "        return files_list\n",
    "\n",
    "    def process_folders(self):\n",
    "        \"\"\"Process the folders and create datapoint objects.\"\"\"\n",
    "        for data_folder in self.data_folders:\n",
    "            metadata_subfolder = os.path.join(data_folder, \"metadata\")\n",
    "            pose_subfolder = os.path.join(data_folder, \"pose\")\n",
    "            rgb_subfolder = os.path.join(data_folder, \"rgb\")\n",
    "            seg_subfolder = os.path.join(data_folder, \"seg\")\n",
    "\n",
    "            # List files in subfolders \n",
    "            metadata_files = self._get_files_in_subfolder(metadata_subfolder, file_extension=\".json\")\n",
    "            pose_files = self._get_files_in_subfolder(pose_subfolder, file_extension=\".json\")\n",
    "            rgb_files = self._get_files_in_subfolder(rgb_subfolder, file_extension=\".png\")\n",
    "            seg_png_files = self._get_files_in_subfolder(seg_subfolder, file_extension=\".png\")\n",
    "            seg_json_files = self._get_files_in_subfolder(seg_subfolder, file_extension=\".json\")\n",
    "\n",
    "            # Make sure the files are indexed and aligned properly (by index) across the subfolders\n",
    "            max_length = max(len(metadata_files), len(pose_files), len(rgb_files), len(seg_png_files), len(seg_json_files))\n",
    "\n",
    "            # Verify that the lengths are the same\n",
    "            if not all(len(files) == max_length for files in [metadata_files, pose_files, rgb_files, seg_png_files, seg_json_files]):\n",
    "                print(f\"Lengths do not match for folder: {data_folder}\")\n",
    "                continue\n",
    "\n",
    "            for i in range(max_length):\n",
    "                # Use index 'i' to fetch corresponding files. If a file doesn't exist, use None.\n",
    "                metadata_filepath = os.path.join(metadata_subfolder, metadata_files[i]) if i < len(metadata_files) else None\n",
    "                pose_filepath = os.path.join(pose_subfolder, pose_files[i]) if i < len(pose_files) else None\n",
    "                rgb_filepath = os.path.join(rgb_subfolder, rgb_files[i]) if i < len(rgb_files) else None\n",
    "                seg_png_filepath = os.path.join(seg_subfolder, seg_png_files[i]) if i < len(seg_png_files) else None\n",
    "                seg_json_filepath = os.path.join(seg_subfolder, seg_json_files[i]) if i < len(seg_json_files) else None\n",
    "\n",
    "                # Create a datapoint object for each corresponding file\n",
    "                data_point = datapoint(metadata_filepath, pose_filepath, rgb_filepath, seg_png_filepath, seg_json_filepath)\n",
    "                self.datapoints.append(data_point)\n",
    "\n",
    "    def get_datapoints(self):\n",
    "        \"\"\"Return the list of datapoint objects.\"\"\"\n",
    "        return self.datapoints\n",
    "    \n",
    "    def get_datapoints_filtered(self):\n",
    "        \"\"\"Return the list of filtered datapoint objects.\"\"\"\n",
    "        return self.datapoints_filtered \n",
    "\n",
    "    def filter_datapoints(self): \n",
    "        \"\"\"Compute the diffusion reflectance and only keep datapoints with positive values.\"\"\"\n",
    "        self.datapoints_filtered = [] \n",
    "        for dp in self.datapoints:\n",
    "            dp.compute_diffusion_reflectance() \n",
    "            if dp.diffuse_reflection > 300: \n",
    "                self.datapoints_filtered.append(dp)\n",
    "\n",
    "    def split_train_val(self, filter=True, frac_train=0.8):\n",
    "        \"\"\"Split the datapoints into training and validation datasets.\"\"\"\n",
    "        if filter: \n",
    "            self.datapoints_train = random.sample(self.datapoints_filtered, int(frac_train * len(self.datapoints_filtered)))\n",
    "            self.datapoints_val = [dp for dp in self.datapoints_filtered if dp not in self.datapoints_train]\n",
    "        else:\n",
    "            self.datapoints_train = random.sample(self.datapoints, int(frac_train * len(self.datapoints)))\n",
    "            self.datapoints_val = [dp for dp in self.datapoints if dp not in self.datapoints_train]\n",
    "\n",
    "    def create_directories(self):\n",
    "        \"\"\"Create directories for training and validation data.\"\"\"\n",
    "        dir_train = os.path.join(self.out_dir, \"train\")\n",
    "        dir_val = os.path.join(self.out_dir, \"val\")\n",
    "        dir_train_rgb = os.path.join(dir_train, \"rgb\")\n",
    "        dir_train_seg = os.path.join(dir_train, \"seg\")\n",
    "        dir_val_rgb = os.path.join(dir_val, \"rgb\")\n",
    "        dir_val_seg = os.path.join(dir_val, \"seg\")\n",
    "\n",
    "        os.makedirs(dir_train_rgb, exist_ok=True)\n",
    "        os.makedirs(dir_train_seg, exist_ok=True)\n",
    "        os.makedirs(dir_val_rgb, exist_ok=True)\n",
    "        os.makedirs(dir_val_seg, exist_ok=True)\n",
    "\n",
    "        return dir_train_rgb, dir_train_seg, dir_val_rgb, dir_val_seg\n",
    "\n",
    "    def preprocess_rgb(self, img_path):  \n",
    "        \"\"\"Preprocess RGB image by resizing it.\"\"\"\n",
    "        # new_size = (480, 270)  # Define the new size\n",
    "        # new_size = (480*2, 270*2)  # Define the new size\n",
    "        img = Image.open(img_path)\n",
    "        # img_resized = img.resize(new_size)\n",
    "        img_resized = img \n",
    "        return img_resized\n",
    "\n",
    "    def preprocess_seg_img(self, seg_img_path, seg_json_path, tag_seg_color=None):\n",
    "        \"\"\"\n",
    "        Preprocesses the segmentation image by resizing and converting it to a binary mask based on tag color.\n",
    "        \"\"\"\n",
    "        # Validate that the segmentation image file exists\n",
    "        if not os.path.exists(seg_img_path):\n",
    "            raise FileNotFoundError(f\"Segmentation image file not found: {seg_img_path}\")\n",
    "\n",
    "        # Validate that the JSON file exists\n",
    "        if not os.path.exists(seg_json_path):\n",
    "            raise FileNotFoundError(f\"Segmentation JSON file not found: {seg_json_path}\")\n",
    "\n",
    "        # Load the segmentation JSON data if tag_seg_color is not provided\n",
    "        if tag_seg_color is None:\n",
    "            with open(seg_json_path, 'r') as json_file:\n",
    "                seg_json = json.load(json_file)\n",
    "\n",
    "            # Find the tag color from the JSON data\n",
    "            for key, val in seg_json.items(): \n",
    "                if val.get(\"class\") == \"tag0\":  \n",
    "                    # Convert the key (which is a string representing a tuple) into an actual tuple\n",
    "                    tag_seg_color = tuple(map(int, key.strip('()').split(', ')))  # Convert string '(140, 25, 255, 255)' into a tuple (140, 25, 255, 255)\n",
    "                    break\n",
    "            else:\n",
    "                # raise ValueError(\"Tag with class 'tag0' not found in JSON.\")\n",
    "                tag_seg_color = tuple([-1,-1,-1,-1]) # impossible color value # FIXME: this is a workaround which can be turned into something more elegant \n",
    "\n",
    "        # Load and resize the segmentation image\n",
    "        seg_img = Image.open(seg_img_path)\n",
    "        # new_size = (480, 270)\n",
    "        # new_size = (480*2, 270*2)\n",
    "        # seg_img_resized = seg_img.resize(new_size)\n",
    "        seg_img_resized = seg_img\n",
    "\n",
    "        # Convert the resized image to a NumPy array\n",
    "        seg_img_resized = np.array(seg_img_resized)\n",
    "\n",
    "        # Check if the image is RGB (3 channels) or RGBA (4 channels) or grayscale (1 channel)\n",
    "        if len(seg_img_resized.shape) == 3:\n",
    "            if seg_img_resized.shape[2] == 3:  # RGB image\n",
    "                # Compare each pixel to the tag color (e.g., RGB triplet)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color[:3], axis=-1)  # Create binary mask for RGB image\n",
    "            elif seg_img_resized.shape[2] == 4:  # RGBA image\n",
    "                # Compare each pixel to the tag color (RGBA)\n",
    "                seg_img_resized = np.all(seg_img_resized == tag_seg_color, axis=-1)  # Create binary mask for RGBA image\n",
    "        else:  # If it's a single channel (grayscale), use it directly\n",
    "            seg_img_resized = seg_img_resized == tag_seg_color  # Compare pixel values directly\n",
    "\n",
    "        # Convert the binary mask to uint8 type (0 or 1)\n",
    "        seg_img_resized = (seg_img_resized).astype(np.uint8) * 255  # Multiply by 255 to match image range\n",
    "\n",
    "        # Convert the binary mask back to an image\n",
    "        seg_img_resized = Image.fromarray(seg_img_resized)\n",
    "\n",
    "        return seg_img_resized\n",
    "\n",
    "    def save_preprocessed_images(self, frac_train=0.8, augmentation=True):\n",
    "        \"\"\"Loop through train and val datapoints and save preprocessed images and segmentation masks.\"\"\"\n",
    "        dir_train_rgb, dir_train_seg, dir_val_rgb, dir_val_seg = self.create_directories()\n",
    "\n",
    "        if augmentation: \n",
    "            transform = A.Compose([\n",
    "                A.RandomShadow(shadow_roi=(0,0,1,1), num_shadows_limit=(1,2), shadow_dimension=4, shadow_intensity_range =(0.5, 0.8), p=0.8),  # Apply random shadows to the image\n",
    "                A.RandomSunFlare(flare_roi=(0,0,1,1), num_flare_circles_range=(10,50), src_radius=100, src_color=(150,150,150), method=\"physics_based\", p=0.8),  # Apply random sun flare to the image, TODO: come back to this, get labels \n",
    "                A.GaussNoise(var_limit=(0,0.05), per_channel=True, p=1),  # Add noise to the image \n",
    "                A.AdvancedBlur(blur_limit=(5,25), p=0.8),  # Apply blur to the image \n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=0.8),  # Apply gamma correction to the image\n",
    "                A.RandomBrightnessContrast(brightness_limit=(-0.25,0.25), contrast_limit=(-0.95,0.95), p=0.8),  # Adjust brightness and contrast\n",
    "                A.ISONoise(intensity=(0.1, 0.5), color_shift=(0.01, 0.05), p=0.8),  # Apply ISO noise to the image \n",
    "            ])\n",
    "\n",
    "        for i, dp in enumerate(self.datapoints_train): \n",
    "            img = self.preprocess_rgb(dp.rgb_filepath) \n",
    "            seg = self.preprocess_seg_img(dp.seg_png_filepath, dp.seg_json_filepath)   \n",
    "            if augmentation: \n",
    "                img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image'])       \n",
    "            img.save(os.path.join(dir_train_rgb, f\"img_{i}.png\")) \n",
    "            seg.save(os.path.join(dir_train_seg, f\"seg_{i}.png\"))\n",
    "\n",
    "        for i, dp in enumerate(self.datapoints_val):\n",
    "            img = self.preprocess_rgb(dp.rgb_filepath) \n",
    "            seg = self.preprocess_seg_img(dp.seg_png_filepath, dp.seg_json_filepath) \n",
    "            if augmentation: \n",
    "                img = Image.fromarray(transform(image=np.array(img)[:,:,:3])['image'])       \n",
    "            img.save(os.path.join(dir_val_rgb, f\"img_{i}.png\")) \n",
    "            seg.save(os.path.join(dir_val_seg, f\"seg_{i}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints: 114182\n",
      "Number of filtered datapoints: 95794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/marker_env/lib/python3.12/site-packages/PIL/ImageFile.py:547\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     fh \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mfileno()\n\u001b[1;32m    548\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m frac_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m     27\u001b[0m processor\u001b[38;5;241m.\u001b[39msplit_train_val(\u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frac_train\u001b[38;5;241m=\u001b[39mfrac_train) \n\u001b[0;32m---> 28\u001b[0m processor\u001b[38;5;241m.\u001b[39msave_preprocessed_images()\n",
      "Cell \u001b[0;32mIn[16], line 295\u001b[0m, in \u001b[0;36mDataProcessor.save_preprocessed_images\u001b[0;34m(self, frac_train, augmentation)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m augmentation: \n\u001b[1;32m    294\u001b[0m         img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(transform(image\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(img)[:,:,:\u001b[38;5;241m3\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m])       \n\u001b[0;32m--> 295\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_train_rgb, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \n\u001b[1;32m    296\u001b[0m     seg\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_train_seg, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatapoints_val):\n",
      "File \u001b[0;32m~/anaconda3/envs/marker_env/lib/python3.12/site-packages/PIL/Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2568\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/marker_env/lib/python3.12/site-packages/PIL/PngImagePlugin.py:1431\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1428\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1431\u001b[0m     ImageFile\u001b[38;5;241m.\u001b[39m_save(im, _idat(fp, chunk), [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m im\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;241m0\u001b[39m, rawmode)])\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/envs/marker_env/lib/python3.12/site-packages/PIL/ImageFile.py:551\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    549\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 551\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[38;5;28;01mNone\u001b[39;00m, exc)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    553\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/envs/marker_env/lib/python3.12/site-packages/PIL/ImageFile.py:570\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(bufsize)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    571\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_folders = [\n",
    "    \"/home/anegi/abhay_ws/marker_detection_failure_recovery/output/markers_20250305-165003\",\n",
    "    \"/home/anegi/abhay_ws/marker_detection_failure_recovery/output/markers_20250310-005350/\", \n",
    "]\n",
    "\n",
    "# define OUT_DIR based on current date and time \n",
    "OUT_DIR = f\"/home/anegi/abhay_ws/marker_detection_failure_recovery/segmentation_model/data/data_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "# OUT_DIR = f\"/media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/markers_20250305-165003/segmentation_model_data_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True) \n",
    "\n",
    "# Create an instance of the DataProcessor class\n",
    "processor = DataProcessor(data_folders, OUT_DIR)\n",
    "\n",
    "# Process the folders to create the datapoint list\n",
    "processor.process_folders()\n",
    "\n",
    "# Retrieve and print length of the datapoints before and after filtering \n",
    "print(f\"Number of datapoints: {len(processor.datapoints)}\") \n",
    "processor.filter_datapoints() \n",
    "print(f\"Number of filtered datapoints: {len(processor.datapoints_filtered)}\")  \n",
    "\n",
    "# Retrieve filtered datapoints\n",
    "datapoints = processor.get_datapoints_filtered()\n",
    "\n",
    "# Split the datapoints into training and validation sets\n",
    "frac_train = 0.8\n",
    "processor.split_train_val(filter=True, frac_train=frac_train) \n",
    "processor.save_preprocessed_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
