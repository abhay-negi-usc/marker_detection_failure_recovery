{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os \n",
    "from scipy.spatial.transform import Rotation as R \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_json_to_dict(pose_file): \n",
    "    with open(pose_file, 'r') as file:\n",
    "        pose_dict_raw = json.load(file) \n",
    "    # go through each key and convert nested list to np array \n",
    "    pose_dict = {}\n",
    "    for key in pose_dict_raw: \n",
    "        pose_dict[key] = np.array(pose_dict_raw[key])\n",
    "\n",
    "    # compute output data \n",
    "    # compute incident angle of light between plane z axis and light -z axis \n",
    "    tag_plane_normal = pose_dict[\"tag\"][:3,2] \n",
    "    light_direction = pose_dict[\"light\"][:3,2]  \n",
    "    cam_direction = -pose_dict[\"cam\"][:3,2] \n",
    "    pose_dict[\"tag_light_angle_of_incidence\"] = np.arccos(np.dot(tag_plane_normal, light_direction) / (np.linalg.norm(tag_plane_normal) * np.linalg.norm(light_direction))) * 180 / np.pi\n",
    "    return pose_dict \n",
    "\n",
    "def metadata_json_to_dict(metadata_file): \n",
    "    with open(metadata_file, 'r') as file:\n",
    "        metadata_dict = json.load(file) \n",
    "    return metadata_dict \n",
    "\n",
    "def lambertian_reflection(I_incident, N, L):\n",
    "    # Calculate diffuse reflection (Lambertian model)\n",
    "    return I_incident * max(np.dot(N, L), 0)\n",
    "\n",
    "def phong_reflection(I_incident, N, L, V, shininess):\n",
    "    # Calculate the reflection vector\n",
    "    R = (2 * np.dot(N, L) * N) - L\n",
    "    # Calculate specular reflection using the Phong model\n",
    "    return I_incident * max(np.dot(R, V), 0) ** shininess\n",
    "\n",
    "def process_data(metadata_dict, pose_dict): \n",
    "    tag_light_aoi = pose_dict[\"tag_light_angle_of_incidence\"]  \n",
    "    light_exposure = metadata_dict[\"light\"][\"exposure\"] \n",
    "    light_color = metadata_dict[\"light\"][\"color\"]   \n",
    "    # diffuse_reflection = np.max((np.cos(tag_light_aoi * np.pi / 180),0)) * (2**light_exposure) \n",
    "    N = pose_dict[\"tag\"][:3,2] \n",
    "    L = pose_dict[\"light\"][:3,2] \n",
    "    V = pose_dict[\"cam\"][:3,2] \n",
    "    I_incident = 2**light_exposure \n",
    "    shininess = 1.0 # NOTE: placeholder value \n",
    "    diffuse_reflection = lambertian_reflection(I_incident, N, L)     \n",
    "    specular_reflection = phong_reflection(I_incident, N, L, V, shininess)\n",
    "    metadata = {\n",
    "        \"angle of incidence\": tag_light_aoi, \n",
    "        \"light_exposure\": light_exposure, \n",
    "        # \"light_color\": light_color, # FIXME: parse data \n",
    "        \"diffuse_reflection\": diffuse_reflection, \n",
    "        \"specular_reflection\": specular_reflection, \n",
    "    }\n",
    "    return metadata "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READ DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdg_dir = \"/media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/\" \n",
    "# list all files ordered by time of creation \n",
    "files = os.listdir(sdg_dir) \n",
    "files.sort(key=lambda x: os.path.getmtime(os.path.join(sdg_dir, x))) \n",
    "data_dir = files[-1] # get latest data \n",
    "pose_dir = os.path.join(sdg_dir, data_dir, \"pose\") \n",
    "rgb_dir = os.path.join(sdg_dir, data_dir, \"rgb\") \n",
    "seg_dir = os.path.join(sdg_dir, data_dir, \"seg\") \n",
    "metadata_dir = os.path.join(sdg_dir, data_dir, \"metadata\")   \n",
    "\n",
    "# get all files in the directories \n",
    "pose_files = os.listdir(pose_dir) \n",
    "rgb_files = os.listdir(rgb_dir) \n",
    "seg_files = os.listdir(seg_dir) \n",
    "metadata_files = os.listdir(metadata_dir) \n",
    "\n",
    "# filter seg_files to only include .png files \n",
    "seg_files = [f for f in seg_files if f.endswith(\".png\")]\n",
    "\n",
    "# sort the files by time of creation\n",
    "pose_files.sort(key=lambda x: os.path.getmtime(os.path.join(pose_dir, x))) \n",
    "rgb_files.sort(key=lambda x: os.path.getmtime(os.path.join(rgb_dir, x)))\n",
    "seg_files.sort(key=lambda x: os.path.getmtime(os.path.join(seg_dir, x))) \n",
    "metadata_files.sort(key=lambda x: os.path.getmtime(os.path.join(metadata_dir, x))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROCESS RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image 0 to /media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/markers_20250222-220217/summary_images/summary_image_0.png\n",
      "Saved image 1 to /media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/markers_20250222-220217/summary_images/summary_image_1.png\n",
      "Saved image 2 to /media/rp/Elements/abhay_ws/marker_detection_failure_recovery/data/marker_obj_sdg/markers_20250222-220217/summary_images/summary_image_2.png\n"
     ]
    }
   ],
   "source": [
    "# Create the directory for saving images if it doesn't exist\n",
    "output_dir = os.path.join(sdg_dir, data_dir, \"summary_images\") \n",
    "os.makedirs(output_dir, exist_ok=True) \n",
    "\n",
    "# Loop through all indices (images)\n",
    "for idx in range(len(rgb_files)):\n",
    "    rgb_file = os.path.join(rgb_dir, rgb_files[idx])\n",
    "    seg_file = os.path.join(seg_dir, seg_files[idx])\n",
    "    pose_file = os.path.join(pose_dir, pose_files[idx])\n",
    "    metadata_file = os.path.join(metadata_dir, metadata_files[idx]) \n",
    "\n",
    "    # Read data from files\n",
    "    rgb_image = cv2.imread(rgb_file)\n",
    "    seg_image = cv2.imread(seg_file, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    pose_dict = pose_json_to_dict(pose_file) \n",
    "    metadata_dict = metadata_json_to_dict(metadata_file) \n",
    "    metadata = process_data(metadata_dict, pose_dict)\n",
    "\n",
    "    # Check if images are loaded correctly\n",
    "    if rgb_image is None:\n",
    "        raise ValueError(f\"RGB image at {rgb_file} could not be loaded.\")\n",
    "    if seg_image is None:\n",
    "        raise ValueError(f\"Segmentation image at {seg_file} could not be loaded.\")\n",
    "\n",
    "    # Convert from BGR (OpenCV default) to RGB (for matplotlib)\n",
    "    image_rgb = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a new figure for each image\n",
    "    plt.figure(figsize=(12, 6))  # Adjust figure size to make space for metadata\n",
    "\n",
    "    # Subplot for RGB image\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.title(f'RGB Image {idx}')\n",
    "\n",
    "    # Subplot for segmentation image\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.imshow(seg_image, cmap='viridis')  # Use a colormap for better visualization\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.title(f'Segmentation Image {idx}')\n",
    "\n",
    "    # Display metadata as text in a separate area (outside the main image area)\n",
    "    metadata_str = '\\n'.join([f'{key}: {value:.2f}' for key, value in metadata.items()])\n",
    "\n",
    "    # Create a new subplot for metadata\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.text(1.05, 0.5, metadata_str, fontsize=12, ha='left', va='center', transform=plt.gca().transAxes, \n",
    "             bbox=dict(facecolor='white', alpha=0.7, edgecolor='black', boxstyle='round,pad=1'))\n",
    "\n",
    "    # Adjust layout to avoid overlap and make space for metadata\n",
    "    plt.tight_layout()  # Adjust layout\n",
    "    plt.subplots_adjust(right=0.8)  # Make space for metadata on the right\n",
    "\n",
    "    # Save the image to the summary_images folder\n",
    "    save_path = os.path.join(output_dir, f\"summary_image_{idx}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=300)  # Save with high resolution\n",
    "    plt.close()  # Close the plot to free up memory\n",
    "\n",
    "    if len(rgb_files) < 10 or (idx + 1) % (len(rgb_files) // 10) == 0:\n",
    "        print(f\"Saved image {idx} to {save_path}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dp \u001b[38;5;241m=\u001b[39m \u001b[43mdatapoints\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dp\u001b[38;5;241m.\u001b[39mpose_dict)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(dp\u001b[38;5;241m.\u001b[39mrgb_image)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datapoints' is not defined"
     ]
    }
   ],
   "source": [
    "dp = datapoints[-1] \n",
    "\n",
    "print(dp.pose_dict)\n",
    "print(dp.rgb_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marker_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
